#!/bin/bash

# Script para instalar modelos do DeepSeek/Ollama
# Mostra progresso visual durante o download

set -e

# Carregar configura√ß√µes
if [ -f .env ]; then
    source .env
else
    OLLAMA_PORT=11434
    DEFAULT_MODELS="deepseek-v3,qwen2.5-coder:7b"
fi

# Cores para output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Fun√ß√£o para mostrar spinner durante opera√ß√µes
show_spinner() {
    local -r pid="${1}"
    local -r delay='0.1'
    local spinstr='\|/-'
    local temp
    
    while ps a | awk '{print $1}' | grep -q "${pid}"; do
        temp="${spinstr#?}"
        printf " [%c]  " "${spinstr}"
        spinstr=${temp}${spinstr%"${temp}"}
        sleep "${delay}"
        printf "\b\b\b\b\b\b"
    done
    printf "    \b\b\b\b"
}

# Fun√ß√£o para verificar se modelo j√° est√° instalado
model_exists() {
    local model=$1
    docker exec deepseek-ollama ollama list | grep -q "^$model"
}

# Fun√ß√£o para instalar um modelo
install_model() {
    local model=$1
    
    echo -e "${BLUE}üì• Instalando modelo: ${YELLOW}$model${NC}"
    
    if model_exists "$model"; then
        echo -e "${GREEN}‚úÖ Modelo $model j√° est√° instalado${NC}"
        return 0
    fi
    
    echo -e "${YELLOW}‚è≥ Download em progresso... (pode demorar alguns minutos)${NC}"
    echo -e "${YELLOW}üí° Dica: Abra outro terminal para monitorar: docker-compose logs -f ollama${NC}"
    
    # Instalar modelo em background e mostrar progresso
    (docker exec deepseek-ollama ollama pull "$model") &
    local pull_pid=$!
    
    # Mostrar spinner enquanto instala
    show_spinner $pull_pid
    
    # Aguardar processo terminar
    wait $pull_pid
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}‚úÖ Modelo $model instalado com sucesso!${NC}"
        
        # Mostrar tamanho do modelo
        echo -e "${BLUE}üìä Verificando tamanho...${NC}"
        docker exec deepseek-ollama ollama list | grep "$model"
    else
        echo -e "${RED}‚ùå Erro ao instalar modelo $model${NC}"
        return 1
    fi
}

# Fun√ß√£o para listar modelos dispon√≠veis
list_available_models() {
    echo -e "${BLUE}üìã Modelos recomendados para desenvolvimento:${NC}"
    echo ""
    echo -e "${GREEN}Pequenos (4-8GB):${NC}"
    echo "  ‚Ä¢ deepseek-coder:6.7b    - Especialista em c√≥digo"
    echo "  ‚Ä¢ qwen2.5-coder:7b       - √ìtimo para Node/Ruby"
    echo "  ‚Ä¢ codellama:7b           - Meta Code Llama"
    echo ""
    echo -e "${YELLOW}M√©dios (15-25GB):${NC}"
    echo "  ‚Ä¢ deepseek-v3            - Melhor qualidade geral"
    echo "  ‚Ä¢ qwen2.5-coder:32b      - Especialista avan√ßado"
    echo ""
    echo -e "${RED}Grandes (30GB+):${NC}"
    echo "  ‚Ä¢ llama3.3:70b           - M√°xima qualidade"
    echo ""
}

# Fun√ß√£o principal
main() {
    echo -e "${BLUE}ü§ñ DeepSeek Model Installer${NC}"
    echo ""
    
    # Verificar se Ollama est√° rodando
    if ! curl -s http://localhost:${OLLAMA_PORT}/api/tags > /dev/null; then
        echo -e "${RED}‚ùå Ollama n√£o est√° rodando. Execute 'docker-compose up -d' primeiro.${NC}"
        exit 1
    fi
    
    # Se nenhum argumento foi passado, usar DEFAULT_MODELS
    if [ $# -eq 0 ]; then
        if [ ! -z "$DEFAULT_MODELS" ]; then
            echo -e "${YELLOW}üì¶ Instalando modelos padr√£o: $DEFAULT_MODELS${NC}"
            IFS=',' read -ra MODELS <<< "$DEFAULT_MODELS"
            for model in "${MODELS[@]}"; do
                model=$(echo "$model" | xargs) # Remove espa√ßos
                install_model "$model"
                echo ""
            done
        else
            echo -e "${YELLOW}ü§î Nenhum modelo especificado.${NC}"
            list_available_models
            exit 0
        fi
    else
        # Instalar modelos especificados como argumentos
        for model in "$@"; do
            install_model "$model"
            echo ""
        done
    fi
    
    echo -e "${GREEN}üéâ Instala√ß√£o conclu√≠da!${NC}"
    echo ""
    echo -e "${BLUE}üìã Modelos instalados:${NC}"
    docker exec deepseek-ollama ollama list
    echo ""
    echo -e "${YELLOW}üí° Para testar: curl -X POST http://localhost:${OLLAMA_PORT}/api/generate -d '{\"model\":\"deepseek-v3\",\"prompt\":\"Hello world in Node.js\"}'${NC}"
}

# Executar fun√ß√£o principal com todos os argumentos
main "$@"